{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bulldozers price prediction","metadata":{}},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"%config Completer.use_jedi = False\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:55:20.294535Z","iopub.execute_input":"2022-05-01T22:55:20.295196Z","iopub.status.idle":"2022-05-01T22:55:20.317992Z","shell.execute_reply.started":"2022-05-01T22:55:20.295108Z","shell.execute_reply":"2022-05-01T22:55:20.317297Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom fastai.tabular.all import add_datepart, cont_cat_split\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import accuracy_score ","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:02.307954Z","iopub.execute_input":"2022-05-01T22:59:02.308257Z","iopub.status.idle":"2022-05-01T22:59:02.313422Z","shell.execute_reply.started":"2022-05-01T22:59:02.308229Z","shell.execute_reply":"2022-05-01T22:59:02.312837Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"#### Function to display more rows and columns","metadata":{}},{"cell_type":"code","source":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:55:25.608670Z","iopub.execute_input":"2022-05-01T22:55:25.609105Z","iopub.status.idle":"2022-05-01T22:55:25.613826Z","shell.execute_reply.started":"2022-05-01T22:55:25.609055Z","shell.execute_reply":"2022-05-01T22:55:25.612894Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Loading datasets","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/bluebook-for-bulldozers/Train.zip', compression='zip', low_memory=False, parse_dates=['saledate'])\nvalid = pd.read_csv('../input/bluebook-for-bulldozers/Valid.csv', low_memory=False, parse_dates=['saledate'])\ny_valid = pd.read_csv('../input/bluebook-for-bulldozers/ValidSolution.csv', usecols=['SalePrice'])","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:55:34.664500Z","iopub.execute_input":"2022-05-01T22:55:34.664771Z","iopub.status.idle":"2022-05-01T22:55:40.009874Z","shell.execute_reply.started":"2022-05-01T22:55:34.664744Z","shell.execute_reply":"2022-05-01T22:55:40.009014Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"display_all(train.head().T)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:56:00.131560Z","iopub.execute_input":"2022-05-01T22:56:00.131846Z","iopub.status.idle":"2022-05-01T22:56:00.153839Z","shell.execute_reply.started":"2022-05-01T22:56:00.131817Z","shell.execute_reply":"2022-05-01T22:56:00.152998Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:55:47.207257Z","iopub.execute_input":"2022-05-01T22:55:47.207527Z","iopub.status.idle":"2022-05-01T22:55:47.213157Z","shell.execute_reply.started":"2022-05-01T22:55:47.207500Z","shell.execute_reply":"2022-05-01T22:55:47.212300Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Storing the SalePrice column, that is the one we want to predict, in a separate variable and removing it from the train dataset","metadata":{}},{"cell_type":"code","source":"y_train = train.SalePrice\ntrain.drop('SalePrice', axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:56:06.595329Z","iopub.execute_input":"2022-05-01T22:56:06.595886Z","iopub.status.idle":"2022-05-01T22:56:06.809215Z","shell.execute_reply.started":"2022-05-01T22:56:06.595851Z","shell.execute_reply":"2022-05-01T22:56:06.808258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Function to avoid repiting code\ndef per_col(df, funct, apply=False):\n    for col in df.columns:\n        if apply:\n            df[col] = funct(df[col])\n        else:\n            funct(df[col])\n    return df if apply else None","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:56:59.457040Z","iopub.execute_input":"2022-05-01T22:56:59.457328Z","iopub.status.idle":"2022-05-01T22:56:59.462894Z","shell.execute_reply.started":"2022-05-01T22:56:59.457300Z","shell.execute_reply":"2022-05-01T22:56:59.462150Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Quick overview of the values in each column","metadata":{}},{"cell_type":"code","source":"per_col(train, lambda x: print(x.value_counts(dropna=False)))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:01.588793Z","iopub.execute_input":"2022-05-01T22:57:01.589119Z","iopub.status.idle":"2022-05-01T22:57:02.945818Z","shell.execute_reply.started":"2022-05-01T22:57:01.589085Z","shell.execute_reply":"2022-05-01T22:57:02.944976Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Replacing 'None or Unspecified' values for Nan ","metadata":{}},{"cell_type":"code","source":"none_unsp_string = [col for col in train.columns if 'None or Unspecified' in train[col].value_counts()]\n\ntrain[train[none_unsp_string] == 'None or Unspecified'] = np.nan\nvalid[valid[none_unsp_string] == 'None or Unspecified'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:11.317303Z","iopub.execute_input":"2022-05-01T22:57:11.317586Z","iopub.status.idle":"2022-05-01T22:57:16.722313Z","shell.execute_reply.started":"2022-05-01T22:57:11.317558Z","shell.execute_reply":"2022-05-01T22:57:16.721631Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for i in none_unsp_string:\n    print(train[i].value_counts(dropna=False))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:21.399045Z","iopub.execute_input":"2022-05-01T22:57:21.399923Z","iopub.status.idle":"2022-05-01T22:57:21.965073Z","shell.execute_reply.started":"2022-05-01T22:57:21.399882Z","shell.execute_reply":"2022-05-01T22:57:21.964124Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Dropping columns with more than 80% of null values in the training set","metadata":{}},{"cell_type":"code","source":"n_rows = train.shape[0] * 0.2\nfull_cols = train.columns\ntrain.dropna(axis=1, thresh=n_rows, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:27.891931Z","iopub.execute_input":"2022-05-01T22:57:27.892397Z","iopub.status.idle":"2022-05-01T22:57:29.024038Z","shell.execute_reply.started":"2022-05-01T22:57:27.892367Z","shell.execute_reply":"2022-05-01T22:57:29.023141Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Dropping the same columns in the validation and test set\ndropped_cols = list(set(full_cols)- set(train.columns))\nvalid.drop(dropped_cols, axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:32.878040Z","iopub.execute_input":"2022-05-01T22:57:32.878348Z","iopub.status.idle":"2022-05-01T22:57:32.887904Z","shell.execute_reply.started":"2022-05-01T22:57:32.878317Z","shell.execute_reply":"2022-05-01T22:57:32.887174Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Remaining columns","metadata":{"execution":{"iopub.status.busy":"2022-04-29T22:27:37.127088Z","iopub.execute_input":"2022-04-29T22:27:37.127369Z","iopub.status.idle":"2022-04-29T22:27:37.132783Z","shell.execute_reply.started":"2022-04-29T22:27:37.12734Z","shell.execute_reply":"2022-04-29T22:27:37.131645Z"}}},{"cell_type":"code","source":"#From 53 to 24 columns\nprint(train.columns, len(train.columns), sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:35.412179Z","iopub.execute_input":"2022-05-01T22:57:35.412708Z","iopub.status.idle":"2022-05-01T22:57:35.418396Z","shell.execute_reply.started":"2022-05-01T22:57:35.412673Z","shell.execute_reply":"2022-05-01T22:57:35.417612Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(valid.columns, len(valid.columns), sep='\\n')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:37.082808Z","iopub.execute_input":"2022-05-01T22:57:37.083115Z","iopub.status.idle":"2022-05-01T22:57:37.088641Z","shell.execute_reply.started":"2022-05-01T22:57:37.083078Z","shell.execute_reply":"2022-05-01T22:57:37.087741Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train.head().T","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:40.290415Z","iopub.execute_input":"2022-05-01T22:57:40.290713Z","iopub.status.idle":"2022-05-01T22:57:40.307843Z","shell.execute_reply.started":"2022-05-01T22:57:40.290682Z","shell.execute_reply":"2022-05-01T22:57:40.307007Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Checking the percentage of null values per col\nper_col(train, lambda x: print(x.isnull().sum()/train.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:45.491069Z","iopub.execute_input":"2022-05-01T22:57:45.491676Z","iopub.status.idle":"2022-05-01T22:57:46.084494Z","shell.execute_reply.started":"2022-05-01T22:57:45.491641Z","shell.execute_reply":"2022-05-01T22:57:46.083882Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning Categorical Columns\n* Date Column: \\\nExtracting information from the saledate column with the add_datepart function, creating columns like saledate_year, saledate_month, etc. After this process, the saledate column is dropped, so now we dont have any column with date data type.","metadata":{}},{"cell_type":"code","source":"add_datepart(train, 'saledate')\nadd_datepart(valid, 'saledate')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:54.246215Z","iopub.execute_input":"2022-05-01T22:57:54.247156Z","iopub.status.idle":"2022-05-01T22:57:55.118518Z","shell.execute_reply.started":"2022-05-01T22:57:54.247106Z","shell.execute_reply":"2022-05-01T22:57:55.117683Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def null_columns(df):\n    '''\n    Create a column_name_is_null column\n    to indicate before imputing and encoding\n    that that row had a null value\n    '''\n    for col in df.columns:\n            df[col + '_isnull'] = df[col].isnull()\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:57:58.476324Z","iopub.execute_input":"2022-05-01T22:57:58.476637Z","iopub.status.idle":"2022-05-01T22:57:58.481596Z","shell.execute_reply.started":"2022-05-01T22:57:58.476603Z","shell.execute_reply":"2022-05-01T22:57:58.480870Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train = null_columns(train)\ntrain.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:58:01.028222Z","iopub.execute_input":"2022-05-01T22:58:01.028927Z","iopub.status.idle":"2022-05-01T22:58:01.574890Z","shell.execute_reply.started":"2022-05-01T22:58:01.028890Z","shell.execute_reply":"2022-05-01T22:58:01.573851Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"valid = null_columns(valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:58:07.363589Z","iopub.execute_input":"2022-05-01T22:58:07.364045Z","iopub.status.idle":"2022-05-01T22:58:07.401714Z","shell.execute_reply.started":"2022-05-01T22:58:07.364011Z","shell.execute_reply":"2022-05-01T22:58:07.401053Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Creating Imputers","metadata":{}},{"cell_type":"code","source":"# Imputer for continous values replacing with mean\ncont_imputer = SimpleImputer(strategy='mean')\n\n# Imputing categorical values with most common value\ncat_imputer = SimpleImputer(strategy='most_frequent')","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:58:09.734662Z","iopub.execute_input":"2022-05-01T22:58:09.734991Z","iopub.status.idle":"2022-05-01T22:58:09.739447Z","shell.execute_reply.started":"2022-05-01T22:58:09.734930Z","shell.execute_reply":"2022-05-01T22:58:09.738457Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"### Defining an encoder to the categorical values","metadata":{}},{"cell_type":"code","source":"ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:58:12.227552Z","iopub.execute_input":"2022-05-01T22:58:12.228227Z","iopub.status.idle":"2022-05-01T22:58:12.232254Z","shell.execute_reply.started":"2022-05-01T22:58:12.228193Z","shell.execute_reply":"2022-05-01T22:58:12.231302Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"### Creating a pipeline with all the preprocessing of categorical columns","metadata":{}},{"cell_type":"code","source":"cat_preprocessor = Pipeline(steps=[\n    ('imputer', cat_imputer),\n    ('encoder', ordinal_encoder)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:58:14.291765Z","iopub.execute_input":"2022-05-01T22:58:14.292505Z","iopub.status.idle":"2022-05-01T22:58:14.296503Z","shell.execute_reply.started":"2022-05-01T22:58:14.292463Z","shell.execute_reply":"2022-05-01T22:58:14.295705Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### Getting categorical and continous columns","metadata":{}},{"cell_type":"code","source":"cont_cols, cat_cols = cont_cat_split(train)\nprint('Continuosu columns: ', cont_cols, end='\\n\\n')\nprint('Categorical columns: ', cat_cols)\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:10.058737Z","iopub.execute_input":"2022-05-01T22:59:10.059253Z","iopub.status.idle":"2022-05-01T22:59:10.116581Z","shell.execute_reply.started":"2022-05-01T22:59:10.059201Z","shell.execute_reply":"2022-05-01T22:59:10.115752Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Applying Imputers to DataFrame","metadata":{}},{"cell_type":"code","source":"# Combining the imputers into a column transformer and specifiying\n# the columns that each of them need to targer\n# The n_jobs=-1 will use all the cpu cores available\npreprocessing = ColumnTransformer(n_jobs=-1,\n    transformers=[\n    ('cont_imp', cont_imputer, cont_cols),\n    ('cat_imp', cat_preprocessor, cat_cols)\n])","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:14.622832Z","iopub.execute_input":"2022-05-01T22:59:14.623169Z","iopub.status.idle":"2022-05-01T22:59:14.628265Z","shell.execute_reply.started":"2022-05-01T22:59:14.623134Z","shell.execute_reply":"2022-05-01T22:59:14.627499Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Defining normalizer to scale the data between 0 and 1\nThis may avoid that the model give evaluates one column more important than other, though is not so important in a Random Forest model, that is the one im going to use","metadata":{}},{"cell_type":"code","source":"# Default range of normalization is 0-1\nnormalizer = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:37.726115Z","iopub.execute_input":"2022-05-01T22:59:37.726685Z","iopub.status.idle":"2022-05-01T22:59:37.731034Z","shell.execute_reply.started":"2022-05-01T22:59:37.726639Z","shell.execute_reply":"2022-05-01T22:59:37.730139Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### RandomForestRegressor as machine learning model","metadata":{}},{"cell_type":"code","source":"model = RandomForestRegressor(n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:40.078097Z","iopub.execute_input":"2022-05-01T22:59:40.078393Z","iopub.status.idle":"2022-05-01T22:59:40.083013Z","shell.execute_reply.started":"2022-05-01T22:59:40.078361Z","shell.execute_reply":"2022-05-01T22:59:40.081920Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Defining the main pipeline with the transformation, normalization and model","metadata":{}},{"cell_type":"code","source":"main_pipeline = Pipeline(steps=[\n    ('column_transformer', preprocessing),\n    ('normalizer', normalizer),\n    ('model', model)\n])\nmain_pipeline.fit(train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T22:59:43.560698Z","iopub.execute_input":"2022-05-01T22:59:43.561426Z","iopub.status.idle":"2022-05-01T23:03:39.321322Z","shell.execute_reply.started":"2022-05-01T22:59:43.561390Z","shell.execute_reply":"2022-05-01T23:03:39.319529Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"### Making the predictions to the validation set","metadata":{}},{"cell_type":"code","source":"predictions = main_pipeline.predict(valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T23:03:46.448932Z","iopub.execute_input":"2022-05-01T23:03:46.449217Z","iopub.status.idle":"2022-05-01T23:03:47.651666Z","shell.execute_reply.started":"2022-05-01T23:03:46.449187Z","shell.execute_reply":"2022-05-01T23:03:47.651008Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Evaluating the model (R^2)","metadata":{}},{"cell_type":"code","source":"main_pipeline.score(valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-05-01T23:03:50.276353Z","iopub.execute_input":"2022-05-01T23:03:50.277057Z","iopub.status.idle":"2022-05-01T23:03:50.830907Z","shell.execute_reply.started":"2022-05-01T23:03:50.277022Z","shell.execute_reply":"2022-05-01T23:03:50.830116Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion: The evaluation of the model gives a coefficient of determination of 0.87, wich is a good result and indicates a good fit of the regression model","metadata":{}}]}